name: Python Package using Conda

on:
  push:
  pull_request:

jobs:
  build-and-test:
    strategy:
      fail-fast: false
      matrix:
        os: [ ubuntu-20.04 ]
        profiler: [ DEFAULT, DLIO_PROFILER ]
        gcc: [10]
    name: ${{ matrix.os }}-${{ matrix.profiler }}-${{ matrix.gcc }}
    runs-on: ${{ matrix.os }}
    env:
      DLIO_PROFILER: ${{ matrix.profiler }}
      CC: gcc-${{ matrix.gcc }}
      CXX: g++-${{ matrix.gcc }}
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python 3.10
      uses: actions/setup-python@v3
      with:
        python-version: 3.10.5
    - uses: actions/cache@v2
      with:
        path: ${{ env.pythonLocation }}
        key: ${{ env.pythonLocation }}-${{ hashFiles('setup.py') }}-${{ hashFiles('dev-requirements.txt') }}
    - name: Install Spack
      uses: kzscisoft/install-spack@v1

    - name: Set up packages.yaml
      run: |
        test -f $GITHUB_WORKSPACE/.spack/etc/spack/packages.yaml || cat > $GITHUB_WORKSPACE/.spack/etc/spack/packages.yaml << 'EOF'
        packages:
          all:
            target: [x86_64]
            providers:
              mpi: [openmpi]
          autoconf:
            buildable: False
            externals:
            - spec: "autoconf@2.69"
              prefix: /usr
          automake:
            buildable: False
            externals:
            - spec: "automake@1.16.1"
              prefix: /usr
          cmake:
            buildable: False
            externals:
            - spec: "cmake@3.22.1"
              prefix: /usr
          libtool:
            buildable: False
            externals:
            - spec: "libtool@2.4.6"
              prefix: /usr
          m4:
            buildable: False
            externals:
            - spec: "m4@1.4.18"
              prefix: /usr
          openmpi:
            buildable: False
            externals:
            - spec: "openmpi@4.0.3"
              prefix: /usr
          pkg-config:
            buildable: False
            externals:
            - spec: "pkg-config@0.29.1"
              prefix: /usr
        EOF
        spack compiler find --scope=user
        if [[ $CC == 'gcc-10' ]]; then
          spack config add "packages:all:compiler:[gcc@10.3.0]"
        fi
    - name: Install DLIO
      run: |
        sudo apt-get install mpich
        python -m pip install --upgrade pip
        pip install --upgrade --upgrade-strategy eager -r dev-requirements.txt
        if [[ $PROFILER == 'DLIO_PROFILER' ]]; then
          git clone https://github.com/hariharan-devarajan/dlio-profiler $GITHUB_WORKSPACE/dlio_profiler
          cd $GITHUB_WORKSPACE/dlio_profiler
          git submodule update --init --recursive
          python -m pip install . 
        fi
    - name: test_gen_data
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 pytest -k  test_gen_data -v
    - name: test_custom_storage_root_gen_data
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 pytest -k  test_storage_root_gen_data  -v
    - name: test_train
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 pytest -k test_train -v
    - name: test_custom_storage_root_train
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 pytest -k test_custom_storage_root_train -v
    - name: test_checkpoint_epoch
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 pytest -k test_checkpoint_epoch -v
    - name: test_checkpoint_step
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 pytest -k  test_checkpoint_step -v
    - name: test_eval
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 pytest -k  test_eval -v
    - name: test_multi_threads
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 pytest -k  test_multi_threads -v
    - name: test-tf-loader-tfrecord
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 python ./src/dlio_benchmark.py workload=resnet50 ++workload.dataset.num_files_train=64 ++workload.workflow.train=False ++workload.workflow.generate_data=True  ++workload.dataset.num_files_train=16 ++workload.dataset.num_samples_per_file=16
        RDMAV_FORK_SAFE=1 mpirun -np 2 python ./src/dlio_benchmark.py workload=resnet50 ++workload.dataset.num_files_train=64 ++workload.workflow.train=True ++workload.workflow.generate_data=False  ++workload.dataset.num_files_train=16 ++workload.dataset.num_samples_per_file=16
    - name: test-torch-loader-npz
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 python ./src/dlio_benchmark.py workload=unet3d ++workload.train.computation_time=0.05 ++workload.evaluation.eval_time=0.01 ++workload.train.epochs=2 ++workload.workflow.train=False ++workload.workflow.generate_data=True ++workload.dataset.num_files_train=16 ++workload.dataset.num_files_eval=16 ++workload.reader.read_threads=2 ++workload.dataset.record_length=4096 ++workload.dataset.record_length_stdev=0
        RDMAV_FORK_SAFE=1 mpirun -np 2 python ./src/dlio_benchmark.py workload=unet3d ++workload.train.computation_time=0.05 ++workload.evaluation.eval_time=0.01 ++workload.train.epochs=2 ++workload.workflow.train=True ++workload.workflow.generate_data=False ++workload.dataset.num_files_train=16 ++workload.dataset.num_files_eval=16 ++workload.reader.read_threads=2  ++workload.dataset.record_length=4096 ++workload.dataset.record_length_stdev=0
    - name: test-tf-loader-npz
      run: |
        touch __init__.py
        export PYTHONPATH=./:$PYTHONPATH
        RDMAV_FORK_SAFE=1 mpirun -np 2 python ./src/dlio_benchmark.py workload=unet3d ++workload.framework=tensorflow ++workload.data_reader.data_loader=tensorflow ++workload.train.computation_time=0.05 ++workload.evaluation.eval_time=0.01 ++workload.train.epochs=2 ++workload.workflow.train=False ++workload.workflow.generate_data=True ++workload.dataset.num_files_train=16 ++workload.dataset.num_files_eval=16 ++workload.reader.read_threads=2  ++workload.dataset.record_length=4096 ++workload.dataset.record_length_stdev=0
        RDMAV_FORK_SAFE=1 mpirun -np 2 python ./src/dlio_benchmark.py workload=unet3d ++workload.framework=tensorflow ++workload.data_reader.data_loader=tensorflow ++workload.train.computation_time=0.05 ++workload.evaluation.eval_time=0.01 ++workload.train.epochs=2 ++workload.workflow.train=True ++workload.workflow.generate_data=False ++workload.dataset.num_files_train=16 ++workload.dataset.num_files_eval=16 ++workload.reader.read_threads=2  ++workload.dataset.record_length=4096 ++workload.dataset.record_length_stdev=0
