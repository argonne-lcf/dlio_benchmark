# 8 node run with 4 GPUs per node and TPSIZE=4 and PPSIZE=8
model: megatron_deepspeed

framework: pytorch

workflow:
  generate_data: False
  train: True
  checkpoint: True

dataset: 
  data_folder: dataset/megatron-deepspeed/
  format: mmap_indexed_binary
  num_files_train: 1
  num_samples_per_file: 277203535
  record_length: 2048
  
reader: 
  data_loader: pytorch
  batch_size: 1024
  read_threads: 1
  file_shuffle: seed
  sample_shuffle: seed

train:
  epochs: 311541
  computation_time: 0.03 # every iteration has 290 steps and each iteration is 8.9 sec.

checkpoint:
  checkpoint_folder: checkpoints/megatron-deepspeed
  steps_between_checkpoints: 1000
  model_size: 30102
  type: all_ranks
  optimization_groups: [1009254400, 865075200, 793600]
  num_layers: 44
  layer_parameters: [129761280, 20971520]
